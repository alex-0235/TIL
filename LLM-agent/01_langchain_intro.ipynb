{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1453382",
   "metadata": {},
   "source": [
    "## Langchain Intro\n",
    "\n",
    "```01-langchain_intro.ipynb```\n",
    "- LLM powered 어플리케이션 제작을 위한 프레임 워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5a97fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89294965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6fb0900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 10, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CArcKP2R8Ndw9xX9So4UCNCXS11vM', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d88248f9-a81c-4a47-b13a-e6f49804d807-0', usage_metadata={'input_tokens': 10, 'output_tokens': 9, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4.1-nano')\n",
    "llm.invoke(\"hello, world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "739ab0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'물론입니다! 번역할 텍스트를 제공해 주세요.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 만약 우리가, 외국어로 메세지가 들어오면 한국어로 번역을 해주는 AI 를 만들고 싶다면?\n",
    "msg = input('외국어를 넣으세요')\n",
    "\n",
    "res = llm.invoke(f'한국어로 번역해줘: {msg}')\n",
    "\n",
    "res.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "154ab242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Mangiamo il pranzo. Cosa sarebbe meglio mangiare?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 39, 'total_tokens': 52, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CArc936ta7RRx1Q4YwnHHEUyk8lIv', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--97330732-8234-4c28-9941-c4dc89e6023e-0', usage_metadata={'input_tokens': 39, 'output_tokens': 13, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    # 채팅 세션의 전체적인 안내 사항\n",
    "    SystemMessage(content='한국어를 이탈리어로 번역해줘'),\n",
    "    HumanMessage(content='점심을 먹자. 뭘 먹는게 좋을까?')\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024892c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "548020b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sono sazio.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 27, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CArc9QngQzkEVrJTVbaoC054bTG8p', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--673fb401-66aa-4dd7-8229-8db91f394683-0', usage_metadata={'input_tokens': 27, 'output_tokens': 4, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    {'role': 'system', 'content': '한국어를 이탈리어로 번역해줘'},\n",
    "    {'role': 'user', 'content': '배부르다'}\n",
    "]\n",
    "\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "80599b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Sono| sa|zio|.||"
     ]
    }
   ],
   "source": [
    "for token in llm.stream(messages):\n",
    "    print(token.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260e1f87",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "- 고정된 문자열과 변수를 조합하여 프롬프트를 만드는 방법\n",
    "\n",
    "## Chain\n",
    "- Langchain의 각 구성요소를 묶어서(chaining) 한번에 실행(invoke) 할 수 있도록 하는 기능\n",
    "- `a | b | c` 형태로 나옴. 이건 Python 문법이 아니라 Langchain 문법(Ldel-Langchain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "499d2f79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='寿司が食べたいです', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 24, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CArcAcC3aLfrmdN4AzSb40Tt41XFG', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--b398cf01-6b85-46d2-8893-2416419f173f-0', usage_metadata={'input_tokens': 24, 'output_tokens': 7, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "messages = [\n",
    "    {'role': 'system', 'content': 'Translate Korean to {lang}'},\n",
    "    {'role': 'human', 'content': '{text}'}\n",
    "]\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "prompt = prompt_template.invoke({'lang': '일본어', 'text': '초밥이 먹고싶다'})\n",
    "\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e37cc424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat a burger.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 22, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_e91a518ddb', 'id': 'chatcmpl-CArcByGSGyBfI5TkWtxSnQddjY6ID', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--bbfac9db-4595-4e4e-bc82-92edc5c47070-0', usage_metadata={'input_tokens': 22, 'output_tokens': 7, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = prompt_template.invoke({'lang': '영어', 'text': '버거가 먹고싶다'})\n",
    "llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ea8ffb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I want to eat kimchi jjigae.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 24, 'total_tokens': 34, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-nano-2025-04-14', 'system_fingerprint': 'fp_c4c155951e', 'id': 'chatcmpl-CArcBUmchhhqjiMCDI55XGMJBYpK4', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--27347ae7-4af5-405a-9228-72a053a2c05d-0', usage_metadata={'input_tokens': 24, 'output_tokens': 10, 'total_tokens': 34, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt_template | llm \n",
    "\n",
    "chain.invoke({'lang': '영어', 'text': '김치찌게가 먹고 싶어요'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d14da0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요! 2025년 전반기(1월~6월) 매출 분석을 위한 EDA(탐색적 데이터 분석) 단계별 과정을 아래와 같이 나누어 제안드립니다.\n",
      "\n",
      "1. 데이터 수집 및 준비\n",
      "   - 매출 관련 데이터 수집 (영수증, 거래내역, POS 데이터 등)\n",
      "   - 데이터 통합 및 정제 (중복 제거, 결측치 처리, 포맷 일관성 확보)\n",
      "2. 데이터 탐색 및 기초 통계 분석\n",
      "   - 데이터 구조 파악 (컬럼명, 데이터 타입, 범위)\n",
      "   - 기술 통계량 확인 (평균, 중앙값, 표준편차, 분포 등)\n",
      "   - 전체 매출, 거래 수, 고객 수 등의 기본 통계 파악\n",
      "3. 시간별 매출 트렌드 분석\n",
      "   - 월별/주별/일별 매출 추이 시각화\n",
      "   - 계절성, 주기성 파악\n",
      "4. 제품/서비스별 매출 분석\n",
      "   - 인기 상품, 매출 기여도 높은 제품군 파악\n",
      "   - 카테고리별 매출 비중 분석\n",
      "5. 고객 분석\n",
      "   - 고객 세분화 (고객 유형, 구매 빈도, 평균 구매액 등)\n",
      "   - 신규 고객 vs 재구매 고객 매출 기여도\n",
      "6. 지역별 분석 (지리적 분석이 가능할 경우)\n",
      "   - 지역별 매출 분포 및 성과 분석\n",
      "7. 이상치 및 특이값 검토\n",
      "   - 비정상적 거래나 데이터 이상치 탐지 및 처리\n",
      "8. 인사이트 도출 및 시각화\n",
      "   - 핵심 결과 시각화 (그래프, 차트 등)\n",
      "   - 주요 인사이트와 결론 도출\n",
      "9. 추가 분석 요청 준비\n",
      "   - 필요 시 클러스터링, 연관 규칙 분석 등 후속 분석 설계\n",
      "\n",
      "이 단계별 과정을 따라 진행하시면, 2025년 전반기 매출에 대한 포괄적이고 심층적인 이해를 얻을 수 있습니다. 궁금한 점 있으시면 언제든 문의 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 단발성 명령 수행\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "당신은 클라이언트 요구사항을 분석해서 단계를 나눠주는 데이터분석 전문가 입니다.\n",
    "사용자의 질문은 EDA에 활용할 수 있도로 단계를 나눠주세요\n",
    "\n",
    "질문\" {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "res = chain.invoke({'question': '이번 2025년 전반기 매출 분석'})\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539f475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^물^론^입니다^.^ ^202^5^년^ 전^반^기^(^1^월^~^6^월^)^ 매^출^ 분석^을^ 위한^ E^DA^(^탐^색^적^ 데이터^ 분석^)^ 단^계를^ 아래^와^ 같이^ 나^누^어^ 진행^할^ 수^ 있습니다^.\n",
      "\n",
      "^1^.^ 데이터^ 수^집^ 및^ 준비^\n",
      "^  ^ -^ 매^출^ 데이터^,^ 날짜^,^ 제품^ 정보^,^ 고객^ 정보^ 등^ 관련^ 데이터^ 수^집^\n",
      "^  ^ -^ 데이터^ 통^합^ 및^ 정^제^ (^결^측^치^ 처리^,^ 이상^치^ 탐^지^ 등^)\n",
      "^2^.^ 데이터^ 이해^와^ 기^초^ 통^계^ 분석^\n",
      "^  ^ -^ 데이터^ 구조^ 파^악^ (^컬^럼^명^,^ 데이터^ 타입^ 등^)\n",
      "^  ^ -^ 기^초^ 통^계^량^ 산^출^ (^평^균^,^ 중앙^값^,^ 표^준^편^차^ 등^)\n",
      "^  ^ -^ 날짜^별^,^ 제품^별^,^ 고객^별^ 매^출^ 분^포^ 파^악^\n",
      "^3^.^ 시^계^열^ 분석^ 준비^\n",
      "^  ^ -^ 날짜^ 기준^ 매^출^ 시^계^열^ 데이터^ 생성^\n",
      "^  ^ -^ 월^별^,^ 분^기^별^,^ 일^별^ 매^출^ 트^렌^드^ 확인^\n",
      "^4^.^ 시^각^적^ 탐^색^\n",
      "^  ^ -^ 시^계^열^ 차^트^(^라인^ 차^트^ 등^)를^ 통해^ 매^출^ 추^이^ 시^각^화^\n",
      "^  ^ -^ 히^트^맵^ 또는^ 열^지도^ 등을^ 활용^한^ 시간^별^,^ 제품^별^ 매^출^ 패^턴^ 분석^\n",
      "^5^.^ 세^부^ 특^성^ 분석^\n",
      "^  ^ -^ 제품^별^,^ 고객^군^별^ 매^출^ 기^여^도^ 파^악^\n",
      "^  ^ -^ 매^출^ 성^과^가^ 높은^ 시즌^ 또는^ 이벤트^ 시^기^ 분석^\n",
      "^6^.^ 이상^치^ 및^ 패^턴^ 탐^색^\n",
      "^  ^ -^ 비^정^상^적^ 갑^작^스^러운^ 상승^/^하^락^ 구^간^ 식^별^\n",
      "^  ^ -^ 이상^치^ 또는^ 특^이^ 케^이스^ 분석^\n",
      "^7^.^ 결^론^ 도^출^ 및^ 인^사이트^ 정^리^\n",
      "^  ^ -^ 분석^ 결과^ 요^약^\n",
      "^  ^ -^ 향^후^ 전략^ 도^출^을^ 위한^ 인^사이트^ 정^리^\n",
      "\n",
      "^이^러한^ 단계^별^ 접근^을^ 통해^ ^202^5^년^ 전^반^기^ 매^출^ 데이터를^ 체^계^적으로^ 분석^할^ 수^ 있습니다^.^ 추가^로^ 구^체^적인^ 데이터^ 구조^나^ 목표^에^ 따라^ 세^부^ 단계^는^ 조^정^ 가능합니다^.^^"
     ]
    }
   ],
   "source": [
    "\n",
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='^', flush=True)\n",
    "\n",
    " # '^'에 의해 표시됨. ''만 하면 ^는 빠짐. (하단 참조)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6de98c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "물론입니다. 2025년 전반기 매출 분석을 위한 데이터 분석 단계는 다음과 같이 나눌 수 있습니다:\n",
      "\n",
      "1. **목표 설정 및 요구사항 정의**\n",
      "   - 분석 목적 명확히 하기 (예: 매출 추세 파악, 성장 요인 분석, 문제점 도출)\n",
      "   - 구체적인 질문 또는 KPI 설정 (예: 월별 매출, 상품별 매출 비중, 고객군별 매출 등)\n",
      "\n",
      "2. **데이터 수집 및 확보**\n",
      "   - 2025년 1월부터 6월까지의 매출 데이터 수집\n",
      "   - 관련 데이터(상품 정보, 고객 정보, 채널 등) 확보\n",
      "   - 데이터 출처 검증 및 정비\n",
      "\n",
      "3. **데이터 전처리**\n",
      "   - 결측값, 이상치 처리\n",
      "   - 데이터 형식 일치화 (날짜 형식, 숫자형, 카테고리화)\n",
      "   - 필요시 데이터 통합 또는 병합\n",
      "\n",
      "4. **탐색적 데이터 분석 (EDA) 수행**\n",
      "   - 기본 통계량 확인 (평균, 중앙값, 표준편차 등)\n",
      "   - 시계열 분석 (월별, 주별 매출 추이 파악)\n",
      "   - 상품별, 채널별, 고객군별 매출 분포 분석\n",
      "   - 상관관계 분석 및 패턴 발견\n",
      "   - 이상치 및 특이값 발견\n",
      "\n",
      "5. **시각화 및 인사이트 도출**\n",
      "   - 트렌드 차트, 히스토그램, 박스플롯 등 다양한 시각화 활용\n",
      "   - 매출 변화 요인 식별\n",
      "   - 핵심 인사이트 및 문제점 파악\n",
      "\n",
      "6. **보고서 작성 및 검증**\n",
      "   - 분석 결과 요약 및 결론 정리\n",
      "   - 이해관계자에게 전달할 보고서 또는 프레젠테이션 준비\n",
      "   - 추가 질문 또는 분석 방향 검토\n",
      "\n",
      "7. **추가 분석/모델링 (필요시)**\n",
      "   - 매출 예측 모델링\n",
      "   - 고객 세분화 또는 추천 시스템 등 심화 분석 고려\n",
      "\n",
      "이러한 단계들을 따라 체계적으로 분석을 수행하면 2025년 전반기 매출에 대한 깊이 있는 인사이트를 도출할 수 있습니다."
     ]
    }
   ],
   "source": [
    "for token in chain.stream({'question': '이번 2025년 전반기 매출 분석'}):\n",
    "    print(token, end='', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e7d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate.from_template('{topic}')\n",
    "\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "chain.batch([\n",
    "    {topic: }\n",
    "\n",
    "\n",
    "\n",
    "])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
